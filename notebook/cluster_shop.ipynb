{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c771059-87bb-45de-ae4e-5deeb0546552",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a1a01-dff8-4703-b3f1-a827d3374b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", dpi=200)\n",
    "import hdbscan\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "from spike_psvae import cluster, merge_split_cleaned, cluster_viz_index, denoise, cluster_utils, triage, cluster_viz\n",
    "from spike_psvae.cluster_utils import read_waveforms, compare_two_sorters, make_sorting_from_labels_frames\n",
    "from spike_psvae.cluster_viz import plot_agreement_venn, plot_unit_similarities\n",
    "from spike_psvae.cluster_utils import get_closest_clusters_kilosort_hdbscan\n",
    "from spike_psvae.cluster_viz import plot_single_unit_summary\n",
    "from spike_psvae.cluster_viz import cluster_scatter, plot_waveforms_geom, plot_raw_waveforms_unit_geom, plot_venn_agreement\n",
    "from spike_psvae.cluster_viz import plot_array_scatter, plot_self_agreement, plot_single_unit_summary, plot_agreement_venn, plot_isi_distribution, plot_waveforms_unit_geom, plot_unit_similarities\n",
    "from spike_psvae.cluster_viz import plot_unit_similarity_heatmaps\n",
    "from spike_psvae.cluster_utils import make_sorting_from_labels_frames, compute_cluster_centers, relabel_by_depth, run_weighted_triage, remove_duplicate_units\n",
    "from spike_psvae.cluster_utils import get_agreement_indices, compute_spiketrain_agreement, get_unit_similarities, compute_shifted_similarity, read_waveforms\n",
    "from spike_psvae.cluster_utils import get_closest_clusters_hdbscan, get_closest_clusters_kilosort, get_closest_clusters_hdbscan_kilosort, get_closest_clusters_kilosort_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fbd64-0b0e-4b38-8fcf-abb9d71be20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) #for reproducibility (templates use random waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276bcd8-bbff-4314-9011-32b54112f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/cat/data/'\n",
    "data_name = 'CSH_ZAD_026_5min'\n",
    "data_dir = data_path + data_name + '/'\n",
    "raw_bin = data_dir + 'CSH_ZAD_026_snip.ap.bin'\n",
    "residual_bin = data_dir + 'residual_CSH_ZAD_026_snip.ap_t_0_None.bin'\n",
    "sub_h5 = data_dir + \"subtraction_CSH_ZAD_026_snip.ap_t_0_None.h5\"\n",
    "\n",
    "output_dir = Path(\"/outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87756e2f-b048-4dfd-9bd7-e38e1ccc18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features\n",
    "offset_min = 30 #30 minutes into the recording\n",
    "with h5py.File(sub_h5, \"r\") as h5:\n",
    "    print(h5.keys())\n",
    "    spike_index = h5[\"spike_index\"][:]\n",
    "    x, y, z, alpha, z_rel = h5[\"localizations\"][:].T\n",
    "    maxptps = h5[\"maxptps\"][:]\n",
    "    z_abs = h5[\"z_reg\"][:]\n",
    "    geom = h5[\"geom\"][:]\n",
    "    firstchans = h5[\"first_channels\"][:]\n",
    "    end_sample = h5[\"end_sample\"][()]\n",
    "    start_sample = h5[\"start_sample\"][()]\n",
    "    start_sample += offset_min * 60 * 30000\n",
    "    end_sample += offset_min * 60 * 30000\n",
    "    channel_index = h5[\"channel_index\"][:]\n",
    "    z_reg = h5[\"z_reg\"][:]\n",
    "    tpca_mean = h5[\"tpca_mean\"][:]\n",
    "    tpca_components = h5[\"tpca_components\"][:]\n",
    "    print(\"Loading TPCA from h5\")\n",
    "    tpca = PCA(tpca_components.shape[0])\n",
    "    tpca.mean_ = tpca_mean\n",
    "    tpca.components_ = tpca_components\n",
    "    \n",
    "num_spikes = spike_index.shape[0]\n",
    "end_time = end_sample / 30000\n",
    "start_time = start_sample / 30000\n",
    "recording_duration = end_time - start_time\n",
    "h5 = h5py.File(sub_h5)\n",
    "wfs_subtracted = h5[\"subtracted_waveforms\"]\n",
    "wfs_full_denoise = h5[\"cleaned_waveforms\"]\n",
    "print(f\"duration of recording: {recording_duration} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66ac97-a516-43c9-9557-2afa79378a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load kilosort results\n",
    "data_path = '/media/cat/data/'\n",
    "data_name = 'CSH_ZAD_026_5min'\n",
    "data_dir = data_path + data_name + '/'\n",
    "offset_min = 30\n",
    "\n",
    "kilo_spike_samples = np.load(data_dir + 'kilosort_spk_samples.npy')\n",
    "kilo_spike_frames = (kilo_spike_samples - offset_min*60*30000) #to match our detection alignment\n",
    "kilo_spike_clusters = np.load(data_dir + 'kilosort_spk_clusters.npy')\n",
    "kilo_spike_depths = np.load(data_dir + 'kilosort_spk_depths.npy')\n",
    "kilo_cluster_depth_means = {}\n",
    "kilo_cluster_locations= {}\n",
    "kilo_cluster_templates = {}\n",
    "kilo_cluster_maxptps = {}\n",
    "#create kilosort SpikeInterface sorting\n",
    "sorting_kilo = cluster_utils.make_sorting_from_labels_frames(kilo_spike_clusters, kilo_spike_frames)\n",
    "\n",
    "from spike_psvae.localization import localize_ptp\n",
    "for cluster_id in np.unique(kilo_spike_clusters):\n",
    "    kilo_cluster_depth_means[cluster_id] = np.mean(kilo_spike_depths[kilo_spike_clusters==cluster_id])\n",
    "    waveforms = read_waveforms(np.random.choice(sorting_kilo.get_unit_spike_train(cluster_id), 250), raw_bin, geom, n_times=121)[0]\n",
    "    template = np.mean(waveforms, axis=0)\n",
    "    kilo_cluster_templates[cluster_id] = template\n",
    "    max_chan = np.argmin(np.abs((kilo_cluster_depth_means[cluster_id] - geom[:,1])))\n",
    "    first_chan = max(max_chan-20, 0)\n",
    "    channels = list(range(first_chan, first_chan+40))\n",
    "    template_x, _, template_z_rel, template_z_abs, _, _ = localize_ptp(kilo_cluster_templates[cluster_id].ptp(0)[channels], first_chan, max_chan, geom)\n",
    "    kilo_cluster_locations[cluster_id] = (template_x, template_z_abs)\n",
    "    kilo_cluster_maxptps[cluster_id] = np.max(waveforms.ptp(1),1)\n",
    "    \n",
    "    \n",
    "good_kilo_sort_clusters_all = np.array([  0,  17,  19,  25,  30,  33,  36,  38,  41,  47,  48,  53,  64,\n",
    "        70,  78,  82,  83,  85,  88,  90,  97, 103, 109, 112, 114, 115,\n",
    "       117, 119, 120, 131, 132, 133, 141, 142, 153, 158, 169, 172, 185,\n",
    "       187, 189, 193, 197, 199, 205, 208, 211, 215, 217, 224, 237, 244,\n",
    "       247, 269, 272, 274, 280, 283, 289, 291, 292, 296, 300, 303, 304,\n",
    "       308, 309, 320, 328, 331, 336, 341, 349, 350, 380, 382, 386, 400,\n",
    "       409, 411, 414, 435, 438, 439, 464, 474, 476, 478, 485, 487, 488,\n",
    "       496, 503, 509, 512, 521, 522, 523, 529, 533, 534, 535, 536, 537,\n",
    "       539, 544, 545, 547, 548, 551, 552, 555, 557, 570, 583, 596, 598,\n",
    "       621, 629, 633, 637, 648, 655, 660, 670, 671, 677, 678, 681, 682,\n",
    "       683, 699, 700, 702, 708, 709])\n",
    "\n",
    "#remove empty clusters\n",
    "good_kilo_sort_clusters = []\n",
    "for good_cluster in good_kilo_sort_clusters_all:\n",
    "    if good_cluster in sorting_kilo.get_unit_ids():\n",
    "        good_kilo_sort_clusters.append(good_cluster) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316adf3c-3247-49b6-8c89-2d142eefb7b7",
   "metadata": {},
   "source": [
    "## triage and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c4069-16c2-41b9-bba6-7f8d940abb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty, tz, talpha, tmaxptps, _, ptp_keep, idx_keep  = triage.run_weighted_triage(\n",
    "    x, y, z_reg, alpha, maxptps, threshold=80\n",
    ")\n",
    "idx_keep_full = ptp_keep[idx_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ef4f3-969f-4cf3-b51d-55e5c027c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = denoise.SingleChanDenoiser().load()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "denoiser.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492dee2-2f8f-4fe1-8f05-eb516e2a43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering parameters\n",
    "min_cluster_size = 25\n",
    "min_samples = 25\n",
    "\n",
    "# this will cluster and relabel by depth\n",
    "scales = (1,10,1,15,30) #predefined scales for each feature\n",
    "features = np.c_[tx*scales[0], tz*scales[2], np.log(tmaxptps) * scales[4]]\n",
    "\n",
    "# features = np.c_[tx*scales[0], tz*scales[2], all_pcs[:,0] * alpha1, all_pcs[:,1] * alpha2]\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "clusterer.fit(features)\n",
    "\n",
    "# z order\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "clusterer = cluster_utils.relabel_by_depth(clusterer, cluster_centers)\n",
    "pre_dup_labels = clusterer.labels_.copy()\n",
    "# remove dups and re z order\n",
    "clusterer, duplicate_indices, duplicate_spikes = cluster_utils.remove_duplicate_spikes(clusterer, spike_index[idx_keep_full, 0], tmaxptps, frames_dedup=12)\n",
    "#recompute cluster centers\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "\n",
    "# labels in full index space (not triaged)\n",
    "labels = np.full(x.shape, -1)\n",
    "labels[idx_keep_full] = clusterer.labels_\n",
    "labels_original = labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03630fb6-8b46-45c6-9492-e3c360a31805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z_cutoffs= [(0,550), (500,1050), (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "z_cutoffs= [(500,1000)]#, (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "for z_cutoff in z_cutoffs:\n",
    "    fig, axes = cluster_viz_index.array_scatter(\n",
    "            labels_original[idx_keep_full], geom, tx, tz, tmaxptps, \n",
    "            zlim=z_cutoff,\n",
    "    )\n",
    "    for cluster_id in good_kilo_sort_clusters:\n",
    "        # axes[0].scatter(-25, kilo_cluster_depth_means[cluster_id], marker='x', color='blue')\n",
    "        if len(sorting_kilo.get_unit_spike_train(cluster_id)) > 5:\n",
    "            axes[0].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color='red', s=150)\n",
    "            axes[0].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color='red')\n",
    "            axes[1].scatter(np.max(kilo_cluster_templates[cluster_id].ptp(0)), kilo_cluster_locations[cluster_id][1], marker='x', color='red', s=150)\n",
    "            axes[1].annotate(f\"{cluster_id}\", (np.max(kilo_cluster_templates[cluster_id].ptp(0))+1, kilo_cluster_locations[cluster_id][1]+2.5), color='red')\n",
    "            # axes[2].scatter(-25, kilo_cluster_depth_means[cluster_id], marker='x', color='blue')\n",
    "            axes[2].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color='red', s=150)\n",
    "            axes[2].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color='red')\n",
    "            axes[0].set_xlim(-20, 80)\n",
    "            axes[1].set_xlim(0, 30)\n",
    "            axes[2].set_xlim(-20, 80)\n",
    "    # for go\n",
    "    # fig.savefig(f\"{save_dir_path}/full_scatter_{z_cutoff[0]}_{z_cutoff[1]}\", dpi=200)\n",
    "    # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262b9e0-a5ec-40bf-8f09-9a22aa8682d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = merge_split_cleaned.get_templates(\n",
    "    raw_bin, geom, clusterer.labels_.max()+1, spike_index[idx_keep_full], clusterer.labels_\n",
    ")\n",
    "\n",
    "template_shifts, template_maxchans, shifted_triaged_spike_index, idx_not_aligned = merge_split_cleaned.align_spikes_by_templates(\n",
    "    clusterer.labels_, templates, spike_index[idx_keep_full]\n",
    ")\n",
    "\n",
    "shifted_full_spike_index = spike_index.copy()\n",
    "shifted_full_spike_index[idx_keep_full] = shifted_triaged_spike_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294cdbd-ab01-42f1-bcf8-282fcac454a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split\n",
    "with h5py.File(sub_h5, \"r\") as h5:\n",
    "    labels_split = merge_split_cleaned.split_clusters(\n",
    "        residual_bin, \n",
    "        h5[\"subtracted_waveforms\"], \n",
    "        firstchans, \n",
    "        shifted_full_spike_index,\n",
    "        template_maxchans,\n",
    "        template_shifts,\n",
    "        labels_original, \n",
    "        x, \n",
    "        z_reg, \n",
    "        # maxptps, \n",
    "        geom, \n",
    "        denoiser, \n",
    "        device,\n",
    "        tpca,\n",
    "        n_channels=10,\n",
    "        pca_n_channels=4,\n",
    "        nn_denoise=False,\n",
    "        threshold_diptest=.5,\n",
    "    )    \n",
    "\n",
    "# re-order again\n",
    "clusterer.labels_ = labels_split[idx_keep_full]\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "clusterer = cluster_utils.relabel_by_depth(clusterer, cluster_centers)\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "labels = np.full(x.shape, -1)\n",
    "labels[idx_keep_full] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de488a8d-a33a-4fce-a16e-1d245abc7788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z_cutoffs= [(0,550), (500,1050), (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "z_cutoffs= [(500,1000)]#, (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "for z_cutoff in z_cutoffs:\n",
    "    fig, axes = cluster_viz.array_scatter(\n",
    "            labels_split[idx_keep_full], geom, tx, tz, tmaxptps, \n",
    "            zlim=z_cutoff,\n",
    "    )\n",
    "    for cluster_id in sorting_kilo.get_unit_ids():\n",
    "        if len(sorting_kilo.get_unit_spike_train(cluster_id)) > 25:\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                color = 'red'\n",
    "                alpha = 1\n",
    "            else:\n",
    "                color = 'blue'\n",
    "                alpha = .4\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                axes[0].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_0 = axes[0].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[1].scatter(np.max(kilo_cluster_templates[cluster_id].ptp(0)), kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_1 = axes[1].annotate(f\"{cluster_id}\", (np.max(kilo_cluster_templates[cluster_id].ptp(0))+1, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[2].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_2 = axes[2].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                text_0.set_alpha(alpha)\n",
    "                text_1.set_alpha(alpha)\n",
    "                text_2.set_alpha(alpha)\n",
    "                axes[0].set_xlim(-20, 80)\n",
    "                axes[1].set_xlim(0, 30)\n",
    "                axes[2].set_xlim(-20, 80)\n",
    "            # axes[0].set_xlim(-25, 120)\n",
    "            # axes[2].set_xlim(-25, 120)\n",
    "            # axes[2].set_ylim(200, 500)\n",
    "            # axes[2].set_ylim(200, 500)\n",
    "    # for go\n",
    "    # fig.savefig(f\"{save_dir_path}/full_scatter_{z_cutoff[0]}_{z_cutoff[1]}\", dpi=200)\n",
    "    # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af50382-455e-4118-9831-3e25ba3d0ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get templates\n",
    "templates = merge_split_cleaned.get_templates(\n",
    "    raw_bin, geom, clusterer.labels_.max()+1, spike_index[idx_keep_full], clusterer.labels_\n",
    ")\n",
    "\n",
    "template_shifts, template_maxchans, shifted_triaged_spike_index, idx_not_aligned  = merge_split_cleaned.align_spikes_by_templates(\n",
    "    clusterer.labels_, templates, spike_index[idx_keep_full]\n",
    ")\n",
    "shifted_full_spike_index = spike_index.copy()\n",
    "shifted_full_spike_index[idx_keep_full] = shifted_triaged_spike_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6aa0b-7ce4-4e88-9622-6b7e31bf12df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge\n",
    "with h5py.File(sub_h5, \"r\") as h5:\n",
    "    labels_merged = merge_split_cleaned.get_merged(\n",
    "        residual_bin,\n",
    "        h5[\"subtracted_waveforms\"],\n",
    "        firstchans,\n",
    "        geom,\n",
    "        templates,\n",
    "        template_shifts,\n",
    "        len(templates),\n",
    "        shifted_full_spike_index,\n",
    "        labels,\n",
    "        x,\n",
    "        z_reg,\n",
    "        denoiser,\n",
    "        device,\n",
    "        tpca,\n",
    "        distance_threshold=1.,\n",
    "        threshold_diptest=.5,\n",
    "        nn_denoise=False,\n",
    "    )\n",
    "    \n",
    "# re-order again\n",
    "clusterer.labels_ = labels_merged[idx_keep_full]\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "clusterer = cluster_utils.relabel_by_depth(clusterer, cluster_centers)\n",
    "cluster_centers = cluster_utils.compute_cluster_centers(clusterer)\n",
    "labels = np.full(x.shape, -1)\n",
    "labels[idx_keep_full] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de577eaa-d03b-4885-9a43-3e273f0cd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_cutoffs= [(0,550), (500,1050), (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "z_cutoffs= [(500,1000)]#, (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "for z_cutoff in z_cutoffs:\n",
    "    fig, axes = cluster_viz.array_scatter(\n",
    "            labels_merged[idx_keep_full], geom, tx, tz, tmaxptps, \n",
    "            zlim=z_cutoff,\n",
    "    )\n",
    "    for cluster_id in sorting_kilo.get_unit_ids():\n",
    "        if len(sorting_kilo.get_unit_spike_train(cluster_id)) > 25:\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                color = 'red'\n",
    "                alpha = 1\n",
    "            else:\n",
    "                color = 'blue'\n",
    "                alpha = .4\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                axes[0].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_0 = axes[0].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[1].scatter(np.max(kilo_cluster_templates[cluster_id].ptp(0)), kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_1 = axes[1].annotate(f\"{cluster_id}\", (np.max(kilo_cluster_templates[cluster_id].ptp(0))+1, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[2].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_2 = axes[2].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                text_0.set_alpha(alpha)\n",
    "                text_1.set_alpha(alpha)\n",
    "                text_2.set_alpha(alpha)\n",
    "                axes[0].set_xlim(-20, 80)\n",
    "                axes[1].set_xlim(0, 30)\n",
    "                axes[2].set_xlim(-20, 80)\n",
    "    # fig.savefig(f\"{save_dir_path}/full_scatter_{z_cutoff[0]}_{z_cutoff[1]}\", dpi=200)\n",
    "    # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46911fe-abc1-4712-90dd-219438c37a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###hdbscan\n",
    "import os\n",
    "save_dir_path = \"clustering_results_split_merge\"\n",
    "if not os.path.exists(save_dir_path):\n",
    "    os.makedirs(save_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e0357-b176-472f-a906-38bfa79c74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cutoffs= [(0,550), (500,1050), (1000,1550), (1500,2050), (2000,2550), (2500,3050), (3000,3550), (3500,4050)]\n",
    "for z_cutoff in z_cutoffs:\n",
    "    fig, axes = cluster_viz.array_scatter(\n",
    "            clusterer.labels_, geom, tx, tz, tmaxptps, \n",
    "            zlim=z_cutoff,\n",
    "    )\n",
    "    for cluster_id in sorting_kilo.get_unit_ids():\n",
    "        if len(sorting_kilo.get_unit_spike_train(cluster_id)) > 25:\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                color = 'red'\n",
    "                alpha = 1\n",
    "            else:\n",
    "                color = 'blue'\n",
    "                alpha = .4\n",
    "            if cluster_id in good_kilo_sort_clusters:\n",
    "                axes[0].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_0 = axes[0].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[1].scatter(np.max(kilo_cluster_templates[cluster_id].ptp(0)), kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_1 = axes[1].annotate(f\"{cluster_id}\", (np.max(kilo_cluster_templates[cluster_id].ptp(0))+1, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                axes[2].scatter(kilo_cluster_locations[cluster_id][0], kilo_cluster_locations[cluster_id][1], marker='x', color=color, s=100, alpha=alpha)\n",
    "                text_2 = axes[2].annotate(f\"{cluster_id}\", (kilo_cluster_locations[cluster_id][0]+2.5, kilo_cluster_locations[cluster_id][1]+2.5), color=color)\n",
    "                text_0.set_alpha(alpha)\n",
    "                text_1.set_alpha(alpha)\n",
    "                text_2.set_alpha(alpha)\n",
    "                axes[0].set_xlim(-20, 80)\n",
    "                axes[1].set_xlim(0, 30)\n",
    "                axes[2].set_xlim(-20, 80)\n",
    "    fig.savefig(f\"{save_dir_path}/full_scatter_{z_cutoff[0]}_{z_cutoff[1]}\", dpi=200)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21880cfd-9530-4a20-ba40-8990f51815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "save_dir_parallel = save_dir_path + \"/unit_summaries\"\n",
    "###hdbscan###\n",
    "if not os.path.exists(save_dir_parallel):\n",
    "    os.makedirs(save_dir_parallel)\n",
    "\n",
    "for cluster_id in np.setdiff1d(np.unique(clusterer.labels_), [-1]):\n",
    "    fig = plot_single_unit_summary(\n",
    "        cluster_id,\n",
    "        labels,\n",
    "        spike_index,\n",
    "        cluster_centers,\n",
    "        geom,\n",
    "        x,\n",
    "        z,\n",
    "        maxptps,\n",
    "        firstchans,\n",
    "        wfs_full_denoise,\n",
    "        wfs_subtracted,\n",
    "        raw_bin,\n",
    "        residual_bin,\n",
    "        num_spikes_plot=100, \n",
    "        num_rows_plot=3, \n",
    "        t_range=(30,90), \n",
    "        plot_all_points=False, \n",
    "        num_channels=40\n",
    "    )\n",
    "    save_z_int = int(cluster_centers.loc[cluster_id][1])\n",
    "    save_str = str(save_z_int).zfill(4)\n",
    "    fig.savefig(save_dir_parallel + f\"/Z{save_str}_cluster{cluster_id}.png\", transparent=False, pad_inches=0)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be503336-6e94-4157-a7a9-209f92d15ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_close_clusters = 50\n",
    "num_close_clusters_plot=10\n",
    "num_channels_similarity = 20\n",
    "shifts_align=np.arange(-8,9)\n",
    "num_channels = 40\n",
    "num_spikes_plot = 100\n",
    "\n",
    "save_dir_similarity = save_dir_path + \"/kilo_venns_similarities\"\n",
    "###hdbscan###\n",
    "if not os.path.exists(save_dir_similarity):\n",
    "    os.makedirs(save_dir_similarity)\n",
    "    \n",
    "for good_cluster_id in good_kilo_sort_clusters:\n",
    "    cluster_id_kilo = good_cluster_id\n",
    "    cluster_id = int(cmp_kilo.get_best_unit_match1(cluster_id_kilo))    \n",
    "    if cluster_id != -1:\n",
    "        st_1 = spike_index[:,0][np.where(labels==cluster_id)]\n",
    "        st_2 = sorting_kilo.get_unit_spike_train(cluster_id_kilo)\n",
    "        sorting1_name = \"hdb\"\n",
    "        sorting2_name = \"kilo\"\n",
    "\n",
    "        z_uniq, z_ids = np.unique(geom[:, 1], return_inverse=True)\n",
    "        all_max_ptp = maxptps[labels==cluster_id].max()\n",
    "        scale = (z_uniq[1] - z_uniq[0]) / max(7, all_max_ptp)\n",
    "\n",
    "        firstchans_cluster_sorting1 = firstchans[labels == cluster_id]\n",
    "        mcs_abs_cluster_sorting1 = spike_index[:,1][labels == cluster_id]\n",
    "\n",
    "        spike_depths = kilo_spike_depths[np.where(kilo_spike_clusters==cluster_id_kilo)]\n",
    "        mcs_abs_cluster_sorting2 = np.asarray([np.argmin(np.abs(spike_depth - geom[:,1])) for spike_depth in spike_depths])\n",
    "        firstchans_cluster_sorting2 = (mcs_abs_cluster_sorting2 - 20).clip(min=0)\n",
    "\n",
    "        fig = plot_agreement_venn(cluster_id, cluster_id_kilo, st_1, st_2, firstchans_cluster_sorting1, mcs_abs_cluster_sorting1, firstchans_cluster_sorting2, mcs_abs_cluster_sorting2,\n",
    "                                  geom, raw_bin, scale=scale, sorting1_name=sorting1_name, sorting2_name=sorting2_name, num_channels=40, num_spikes_plot=200, t_range=(30,90), num_rows=3, \n",
    "                                  alpha=.1);\n",
    "        \n",
    "        save_z_int = int(kilo_spike_depths[cluster_id_kilo])\n",
    "        save_str = str(save_z_int).zfill(4)\n",
    "        fig.savefig(save_dir_similarity + f\"/Z{save_str}_kscluster{cluster_id_kilo}_hdbcluster{cluster_id}.png\", transparent=False, pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        #compute K closest hdbscan clsuters\n",
    "        closest_clusters = get_closest_clusters_kilosort_hdbscan(cluster_id_kilo, kilo_cluster_depth_means, cluster_centers, num_close_clusters)\n",
    "        fig = plot_unit_similarities(cluster_id_kilo, closest_clusters, sorting_kilo, sorting_hdbl_t, geom, raw_bin, recording_duration, num_channels, num_spikes_plot, num_channels_similarity=num_channels_similarity, \n",
    "                                     num_close_clusters_plot=num_close_clusters_plot, num_close_clusters=num_close_clusters, shifts_align = shifts_align, order_by ='similarity', normalize_agreement_by=\"both\")\n",
    "        save_z_int = int(kilo_spike_depths[cluster_id_kilo])\n",
    "        save_str = str(save_z_int).zfill(4)\n",
    "        fig.savefig(save_dir_similarity + f\"/Z{save_str}_kscluster{cluster_id_kilo}.png\", transparent=False, pad_inches=0)\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:psvae]",
   "language": "python",
   "name": "conda-env-psvae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
